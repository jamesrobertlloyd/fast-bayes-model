\documentclass[twoside,11pt]{article}

% Any additional packages needed should be included after jmlr2e.
% Note that jmlr2e.sty includes epsfig, amssymb, natbib and graphicx,
% and defines many common macros, such as 'proof' and 'example'.
%
% It also sets the bibliographystyle to plainnat; for more information on
% natbib citation styles, see the natbib documentation, a copy of which
% is archived at http://www.jmlr.org/format/natbib.pdf

\usepackage{jmlr2e}

\usepackage{listings}
%\usepackage{algorithm}
%\usepackage{algorithmic}
\usepackage{amssymb,amsmath}
%\usepackage{graphicx}
\usepackage{preamble}
%\usepackage{natbib}
%%%% REMEMBER ME!
%\usepackage[draft]{hyperref}
\usepackage{hyperref}
\usepackage{color}
\usepackage{url}
%\usepackage{wasysym}
%\usepackage{subfigure}
%\usepackage{tabularx}
\usepackage{booktabs}
%\usepackage{bm}
%\newcommand{\theHalgorithm}{\arabic{algorithm}}
\definecolor{mydarkblue}{rgb}{0,0.08,0.45}
\hypersetup{ %
    pdftitle={},
    pdfauthor={},
    pdfsubject={},
    pdfkeywords={},
    pdfborder=0 0 0,
    pdfpagemode=UseNone,
    colorlinks=true,
    linkcolor=mydarkblue,
    citecolor=mydarkblue,
    filecolor=mydarkblue,
    urlcolor=mydarkblue,
    pdfview=FitH}

\setlength{\marginparwidth}{0.6in}
\input{include/commenting.tex}

%% For submission, make all render blank.
%\renewcommand{\LATER}[1]{}
%\renewcommand{\fLATER}[1]{}
%\renewcommand{\TBD}[1]{}
%\renewcommand{\fTBD}[1]{}
%\renewcommand{\PROBLEM}[1]{}
%\renewcommand{\fPROBLEM}[1]{}
%\renewcommand{\NA}[1]{#1}  %% Note, NA's pass through!

% Definitions of handy macros can go here

% Heading arguments are {volume}{year}{pages}{submitted}{published}{author-full-names}

%\jmlrheading{Volume}{Year}{Pages}{Submitted}{Published}{James Robert Lloyd}

% Short headings should be running head and authors last names

\ShortHeadings{Fast model building notes}{Lloyd et alia}
\firstpageno{1}

\begin{document}

\lstset{language=Lisp,basicstyle=\ttfamily\footnotesize} 

\title{Fast construction of Gaussian process models}

\author{\name James Robert Lloyd \email jrl44@cam.ac.uk \\
       \addr 
       Machine Learning Group \\
       Department of Engineering\\
       University of Cambridge\\
       \AND
       \name Others\dots}

\editor{Editor}

\maketitle

\begin{abstract}
Notes collected whilst testing fast model building ideas.
\end{abstract}

%\begin{keywords}
%  Gaussian processes
%\end{keywords}

\section{Introduction}

Source code is available at \url{https://github.com/jamesrobertlloyd/fast-bayes-model}.

\section{31 March - Defining the problem and potential solutions}

\subsection{Disorganised notes}

How do we keep everything dimensionless?
Are Bayes factors dimensionless - or do we also need to divide by the number of data points?
We can test this for \iid noise and maybe for a single squared exp and see what happens theoretically and empirically.

Approximations to marginal likelihoods
\begin{itemize}
  \item FITC
  \item SoR
  \item Iterative methods (see \eg Skilling)
  \item RKS
\end{itemize}

Taylor series \eg
\begin{eqnarray}
  (A+B)^{-1} & = & (A(I+A^{-1}B))^{-1} \\
             & = & (I + A^{-1}B)^{-1}A^{-1} \\
             & = & A^{-1} - A^{-1}BA^{-1} + A^{-1}BA^{-1}BA^{-1} - \dots
\end{eqnarray}
Will this help us with computing the improvement that a new kernel will bring?

Computing statistics of interest
\begin{itemize}
  \item Correlogram
  \item Periodogram
  \item Q-Q
\end{itemize}
But do we extract features or calculate statistics at several parameter values?
How do we normalise statistics?
Probabilities, or absolute values or something similar?
Some theory and some empicism can help here.
How do we generalise statistics to multi-d data?
Do we compute stats on data or residuals?
Which residuals?

Should I be using FITC/RKS/\dots optimisation in a racing algorithm framework?
Or use the optimised parameters as features for a regression algorithm?

Or should I be directly optimising policies directly.
The action space is growing but so is the parameter space, so maybe there is hope.

To what extent is it safe to use synthetic data and real data.
Am I trying to create models that quickly optimise models when the modelling assumptions are correct or do I want good performance on a random dataset in the wild?

How do I ensure all of my quantities are dimensionless in a relavent way \eg scale factors compared to data, length scales compared across several datasets.

What does a literature search return.
Learning to learn is a thing in different guises - ask Jonas and Isabel for the different words and whether or not people have applied it to learning the structure of models \eg graphical model structure learning.

\newpage

%\appendix
%\section*{Appendix A.}
%Appendix

\vskip 0.2in
\bibliography{library}

\end{document}
